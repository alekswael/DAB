{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aleksander/projects/DAB/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import json\n",
    "import textwrap\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(task='ner', \n",
    "               model='saattrupdan/nbailab-base-ner-scandi', \n",
    "               aggregation_strategy='first')\n",
    "\n",
    "result = ner('Opossums are great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../annotation_experiments/pre_annotations_test.json\", \"r\", encoding=\"utf-8\") as doc1:\n",
    "    anndoc = json.load(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"data\": {\n",
      "      \"text\": \"Opossums are great\",\n",
      "      \"source_dataset\": \"wiki\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "      {\n",
      "        \"model_version\": \"DaCy\",\n",
      "        \"result\": [\n",
      "          {\n",
      "            \"id\": \"1\",\n",
      "            \"from_name\": \"entity_mentions\",\n",
      "            \"to_name\": \"doc_text\",\n",
      "            \"type\": \"labels\",\n",
      "            \"value\": {\n",
      "              \"start\": 0,\n",
      "              \"end\": 9,\n",
      "              \"text\": \"Opossums\",\n",
      "              \"labels\": [\n",
      "                \"PERSON\"\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"model_version\": \"SkandiNER\",\n",
      "        \"result\": [\n",
      "          {\n",
      "            \"id\": \"1\",\n",
      "            \"from_name\": \"entity_mentions\",\n",
      "            \"to_name\": \"doc_text\",\n",
      "            \"type\": \"labels\",\n",
      "            \"value\": {\n",
      "              \"start\": 0,\n",
      "              \"end\": 8,\n",
      "              \"text\": \"Opossums\",\n",
      "              \"labels\": [\n",
      "                \"ORG\"\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"data\": {\n",
      "      \"text\": \"And so is Sherlock Holmes\",\n",
      "      \"source_dataset\": \"wiki\"\n",
      "    },\n",
      "    \"predictions\": [\n",
      "      {\n",
      "        \"model_version\": \"SkandiNER\",\n",
      "        \"result\": [\n",
      "          {\n",
      "            \"id\": \"1\",\n",
      "            \"from_name\": \"entity_mentions\",\n",
      "            \"to_name\": \"doc_text\",\n",
      "            \"type\": \"labels\",\n",
      "            \"value\": {\n",
      "              \"start\": 0,\n",
      "              \"end\": 8,\n",
      "              \"text\": \"Opossums\",\n",
      "              \"labels\": [\n",
      "                \"ORG\"\n",
      "              ]\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Sample JSON data\n",
    "json_data = anndoc\n",
    "\n",
    "# Sample NER output\n",
    "ner_output = result\n",
    "\n",
    "# Function to update JSON with NER predictions\n",
    "def add_ner_predictions(json_data, ner_output, model_version=\"SkandiNER\"):\n",
    "    for item in json_data:\n",
    "        text = item[\"data\"][\"text\"]\n",
    "        \n",
    "        # Create a new predictions list if it doesn't exist\n",
    "        if \"predictions\" not in item:\n",
    "            item[\"predictions\"] = []\n",
    "\n",
    "        # Create a new result list\n",
    "        results = []\n",
    "        for i, entity in enumerate(ner_output, start=1):\n",
    "            results.append({\n",
    "                \"id\": str(i),\n",
    "                \"from_name\": \"entity_mentions\",\n",
    "                \"to_name\": \"doc_text\",\n",
    "                \"type\": \"labels\",\n",
    "                \"value\": {\n",
    "                    \"start\": entity[\"start\"],\n",
    "                    \"end\": entity[\"end\"],\n",
    "                    \"text\": entity[\"word\"],\n",
    "                    \"labels\": [entity[\"entity_group\"]]\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # Append the new model predictions\n",
    "        item[\"predictions\"].append({\n",
    "            \"model_version\": model_version,\n",
    "            \"result\": results\n",
    "        })\n",
    "\n",
    "    return json_data\n",
    "\n",
    "# Update JSON structure with NER predictions\n",
    "updated_json = add_ner_predictions(json_data, ner_output)\n",
    "\n",
    "# Print the updated JSON\n",
    "print(json.dumps(updated_json, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# JSON template\n",
    "json_structure = [\n",
    "    {\n",
    "        \"data\": {\n",
    "            \"text\": \"\",  # Placeholder\n",
    "            \"source_dataset\": \"\"\n",
    "        },\n",
    "        \"predictions\": []  # Empty initially\n",
    "    }\n",
    "]\n",
    "\n",
    "# Sample texts\n",
    "texts = [\n",
    "    {\"text\": \"Opossums are great\", \"source_dataset\": \"wiki\"},\n",
    "    {\"text\": \"And so is Sherlock Holmes\", \"source_dataset\": \"wiki\"}\n",
    "]\n",
    "\n",
    "# Sample NER outputs\n",
    "ner_outputs = {\n",
    "    \"Opossums are great\": [\n",
    "        {'entity_group': 'ANIMAL', 'score': 0.981, 'word': 'Opossums', 'start': 0, 'end': 8}\n",
    "    ],\n",
    "    \"And so is Sherlock Holmes\": [\n",
    "        {'entity_group': 'PERSON', 'score': 0.974, 'word': 'Sherlock Holmes', 'start': 11, 'end': 26}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Function to populate JSON\n",
    "def populate_json(template, texts, ner_outputs, model_version=\"MyNERModel\"):\n",
    "    populated_json = []\n",
    "    \n",
    "    for text_entry in texts:\n",
    "        new_entry = json.loads(json.dumps(template[0]))  # Deep copy template\n",
    "        new_entry[\"data\"][\"text\"] = text_entry[\"text\"]\n",
    "        new_entry[\"data\"][\"source_dataset\"] = text_entry[\"source_dataset\"]\n",
    "\n",
    "        # Insert predictions if available\n",
    "        text = text_entry[\"text\"]\n",
    "        if text in ner_outputs:\n",
    "            results = []\n",
    "            for i, entity in enumerate(ner_outputs[text], start=1):\n",
    "                results.append({\n",
    "                    \"id\": str(i),\n",
    "                    \"from_name\": \"entity_mentions\",\n",
    "                    \"to_name\": \"doc_text\",\n",
    "                    \"type\": \"labels\",\n",
    "                    \"value\": {\n",
    "                        \"start\": entity[\"start\"],\n",
    "                        \"end\": entity[\"end\"],\n",
    "                        \"text\": entity[\"word\"],\n",
    "                        \"labels\": [entity[\"entity_group\"]]\n",
    "                    }\n",
    "                })\n",
    "\n",
    "            new_entry[\"predictions\"].append({\n",
    "                \"model_version\": model_version,\n",
    "                \"result\": results\n",
    "            })\n",
    "        \n",
    "        populated_json.append(new_entry)\n",
    "\n",
    "    return populated_json\n",
    "\n",
    "# Populate JSON structure with text and predictions\n",
    "final_json = populate_json(json_structure, texts, ner_outputs)\n",
    "\n",
    "# Print output\n",
    "print(json.dumps(final_json, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
